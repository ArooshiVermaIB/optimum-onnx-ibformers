{
  "name": "ibformers_extraction",
  "version": "1.0.3",
  "keywords": "models, transformers",
  "category": "model-training",
  "short_description": "Training scripts for transformers",
  "long_description": "Training scripts for transformers",
  "authors": [
    "Instabase"
  ],
  "beta": true,
  "solution_type": "pypkg",
  "model_training": {
    "sources": [
      "ibformers"
    ],
    "function": "ibformers.trainer.docpro_utils.run_train_doc_pro",
    "function_annotator": "ibformers.trainer.ib_utils.run_train_annotator",
    "base_models": [
      {
        "name": "layout_base",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "layoutlm_sl",
          "model_name": "microsoft/layoutlm-base-uncased",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "layout_large",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "layoutlm_sl",
          "model_name": "microsoft/layoutlm-large-uncased",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "layout_multilingual",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": false,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "layoutxlm_sl",
          "model_name": "microsoft/layoutxlm-base",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "layoutv2",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": false,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "layoutlmv2_sl",
          "model_name": "microsoft/layoutlmv2-base-uncased",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "instalm_base",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.7,
          "pipeline_name": "layoutlm_sl",
          "model_name": "instabase/instalm-base-draft",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "SingleQA_base",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "max_no_annotation_examples_share": 0.5,
          "model_name":"bert-base-uncased",
          "pipeline_name": "single_qa",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "legal_natural_language",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "plain_sl",
          "model_name": "nlpaueb/legal-bert-base-uncased",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      },
      {
        "name": "natural_language",
        "default_hyperparameters": {
          "batch_size": 2,
          "gradient_accumulation_steps": 2,
          "max_length": 512,
          "chunk_overlap": 64,
          "num_train_epochs": 15,
          "learning_rate": 5e-05,
          "lr_scheduler_type": "constant_schedule_with_warmup",
          "use_mixed_precision": true,
          "warmup_ratio": 0.3,
          "weight_decay": 0.001,
          "loss_type": "ce_ins",
          "class_weights_ins_power": 0.3,
          "max_no_annotation_examples_share": 0.5,
          "pipeline_name": "plain_sl",
          "model_name": "bert-base-uncased",
          "early_stopping_patience": 0,
          "validation_set_size": 0.0,
          "do_hyperparam_optimization": false,
          "hp_search_num_trials": 20
        }
      }
    ]
  }
}
