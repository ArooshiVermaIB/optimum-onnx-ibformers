_default:
  name: Custom_model
  hyperparams: &defaults
    adam_epsilon: 1.e-8
    per_device_train_batch_size: 8
    per_device_train_eval_size: 8
    gradient_accumulation_steps: 1
    max_length: 512
    chunk_overlap: 64
    num_train_epochs: 15
    learning_rate: 5.e-5
    optimizer_type: AdamW
    scheduler_type: constant_with_warmup
    fp16: true
    warmup_ratio: 0.0
    weight_decay: 0
    do_train: true
    do_eval: true
    do_predict: true

microsoft/layoutlm-base-uncased:
  name: layout_base
  hyperparams:
    <<: *defaults
    pipeline_name: layoutlm_sl

microsoft/layoutxlm-base:
  name: layout_multilingual
  hyperparams:
    <<: *defaults
    pipeline_name: layoutxlm_sl

microsoft/layoutlmv2-base-uncased:
  name: layoutv2
  hyperparams:
    <<: *defaults
    pipeline_name: layoutlmv2_sl

instabase/laymqav1-base:
  name: LayoutMultiQA_base
  hyperparams:
    <<: *defaults
    pipeline_name: laymqav1

nlpaueb/legal-bert-base-uncased:
  name: legal_natural_language
  hyperparams:
    <<: *defaults
    pipeline_name: plain_sl

bert-base-uncased:
  name: natural_language
  hyperparams:
    <<: *defaults
    pipeline_name: plain_sl

microsoft/layoutlm-large-uncased:
  name: layout_large
  hyperparams:
    <<: *defaults
    per_device_train_batch_size: 4
    per_device_train_eval_size: 4
    gradient_accumulation_steps: 2
    pipeline_name: layoutlm_sl

microsoft/layoutlmv2-large-uncased:
  name: layoutv2_base (single-page)
  hyperparams:
    <<: *defaults
    per_device_train_batch_size: 2
    per_device_train_eval_size: 2
    gradient_accumulation_steps: 4
    pipeline_name: layoutlmv2_sl

